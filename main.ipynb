{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install requests beautifulsoup4 pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from autogen import ConversableAgent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1=\"https://en.wikipedia.org/wiki/University_of_California,_Berkeley\"\n",
    "url_2=\"https://en.wikipedia.org/wiki/Stanford_University\"\n",
    "\n",
    "res_1=requests.get(url_1)\n",
    "res_2=requests.get(url_2)\n",
    "\n",
    "content_1=\"\"\n",
    "content_2=\"\"\n",
    "\n",
    "if res_1.status_code==200 and res_2.status_code==200:\n",
    "    # print(\"content\",)\n",
    "    soup_1=BeautifulSoup(res_1.content,'html.parser')\n",
    "    paras_1=soup_1.find_all('p')\n",
    "    soup_2=BeautifulSoup(res_2.content,'html.parser')\n",
    "    paras_2=soup_2.find_all('p')\n",
    "\n",
    "    for p1, p2 in zip(paras_1,paras_2):\n",
    "        content_1 += p1.get_text()\n",
    "        content_2 += p2.get_text()\n",
    "\n",
    "# To handle both urls having different lengths\n",
    "\n",
    "    if len(paras_1) > len(paras_2):\n",
    "        for p in paras_1[len(paras_2):]:\n",
    "            content_1 += p.get_text()\n",
    "    elif len(paras_2) > len(paras_1):\n",
    "        for p in paras_2[len(paras_1):]:\n",
    "            content_2 += p.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content_1)\n",
    "print(\"----------------------------\")\n",
    "print(content_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_1 = ConversableAgent(\n",
    "    \"summariser\",\n",
    "    system_message=\"You are a summariser. You will be provided with content scraped from a website and you need to summarise the content provided to you with key points. Also at the end of your response return the category of the content provided to you.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.getenv('OPENAI_API_KEY')}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "reply_1 = agent_1.generate_reply(messages=[{\"content\": content_1, \"role\": \"user\"}])\n",
    "print(reply_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_2 = ConversableAgent(\n",
    "    \"summariser\",\n",
    "    system_message=\"You are a summariser. You will be provided with content scraped from a website and you need to summarise the content provided to you with key points. Also at the end of your response return the category of the content provided to you.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.getenv('OPENAI_API_KEY')}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "reply_2 = agent_2.generate_reply(messages=[{\"content\": content_2, \"role\": \"user\"}])\n",
    "print(reply_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_3=ConversableAgent('Comparison_Agent', \n",
    "                         \"You are provided with a user query and summarised web scrapped content from two different websites that belong to the same subject area or category. Your job is to anser the user query by analysing the two contents passed to you and provide appropirate response. Be precise and make sure your response structure has two things, 1.your thought process in brief on how you arrived at the conclusion, 2.your conclusion. Make sure your conclusion is crisp and to the point do not provide any irrelavant information and ambigious statements.\",\n",
    "                        llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.getenv('OPENAI_API_KEY')}]},\n",
    "                        code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "                        function_map=None,  # No registered functions, by default it is None.\n",
    "                        human_input_mode=\"NEVER\",  # Never ask for human input.                        \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"I have recently graduated from my high school, I have great grades and I live in Boston and I am looking for courses in movie production but I am not sure which school is best for me. Could you please suggest?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response=agent_3.generate_reply(messages=[{'role':'user','content':\"user query: \"+query+\"content 1: \"+content_1+\"content 2: \"+content_2}] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Thought Process\n",
      "To provide a recommendation for courses in movie production, I analyzed the content related to the University of California, Berkeley and Stanford University, focusing on their strengths in film and related programs. While neither content directly addresses specific movie production courses, both universities have notable fine arts and media departments. UC Berkeley has a renowned film archive and media resources, which signifies a strong affinity for film education. On the other hand, Stanford's history of producing projects and connections to Silicon Valley innovation can also be relevant to production courses through a technology-focused curriculum. Considering the user's great grades and location in Boston, I need to suggest schools that not only excel in film production education but also would be accessible to them.\n",
      "\n",
      "### Conclusion\n",
      "Given your interest in movie production, **consider the University of California, Berkeley**, which offers strong resources in film and media studies, including a Film Archive that supports educational endeavors in this area. Although **Stanford University** also offers arts programs, Berkeley's specific focus on film and established media studies make it a more suitable option for your desired studies in movie production. While Berkeley is located in California, explore options for distance education or consider relocating for a full immersive experience in film studies.\n"
     ]
    }
   ],
   "source": [
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
